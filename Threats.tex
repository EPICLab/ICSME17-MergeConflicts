\section{Threats to Validity}\label{threats}
\subsection{Construct}
Interview questions were open-ended and designed to elicit developer opinions about the experiences, difficulties, and perceptions of merge conflicts.
The particular factors and needs were determined after concluding all interviews, and thus did not bias interview participants to only factors previously mentioned.
Survey questions were created using factors found through card-based unitization.
This methodology allowed us to capture the common themes that practitioners experience when working with merge conflicts, but might have allowed themes specific to particular sub-groups to be unrepresented in our results.
\subsection{Internal Validity}
Central tendency bias \cite{guilford1954psychometric} is an issue in studies with 5-point Likert scales, since participants tend to choose less opinionated answers.
We lessen this effect by examining the answers in comparison to each other, as opposed to analysis of absolute mean values.
Because we use this method to highlight stronger answers by degree, this also means that we may have missed subtle trends across our data that may have been visible otherwise.

\subsection{External Validity}
Interview results may not be generalizable to all practitioners due to a small sample size.
In order to reduce this effect, interview participants were selected from open- and closed-source projects, varying industries, and varying project sizes (see Table \ref{interview_demographics}).
To expand and confirm our interview results, we used a survey of 162 practitioners to ensure our results match with trends in the larger software development community.
We also recognize that recruitment of participants through digital communication methods is subject to self-selection bias and non-response bias.

\subsection{Reliability}
It is possible that developer opinions will change over time or with a different group of survey participants. By surveying 162 developers from varying roles, experience levels, and team sizes, we hope to mitigate the generalizability issues associated with small groups of similar participants.

Population sampling, including surveys, are traditionally validated for reliability and reproducibility by disclosure of response rates.
However, we used social media and mailing lists which do not allow accurate measurements of the number of individuals that read our recruitment request.
Therefore we do not report a survey response rate.

For purposes of replication, our interview script and survey questions are available at \cite{companion_site}. 
\todo{Make sure survey questions actually get posted on the website before submitting}

