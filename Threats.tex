\section{Threats to Validity}\label{threats}
\subsection{Construct}
\textbf{Question construction:}
\textit{Are these the right questions to ask?} Interview questions were designed to ask for developer opinions about the causes and difficulties of merge conflicts without asking about particular factors. This prevented researcher biases from promoting any particular factors of difficulty over other potential factors. 
Survey questions were then created using factors that came directly from the survey analysis, resulting in a question construction which came from the data, as interpreted by the first and second authors' negotiated agreement.
\subsection{Internal Validity}
\textbf{Central Tendency Bias:}
Central tendency bias \cite{guilford1954psychometric} is an issue in studies with 5-point Likert scales, since participants tend to choose less opinionated answers. While this threat is still valid, establishing the central range of mean values (3 $\pm$ 0.5) as more moderate answers ensured that any answers above this threshold evoked the strongest developer opinions. Because we use this method to highlight stronger factors in an effort to be conservative, this also means that we may have missed trends across our data that may have been visible otherwise.

\subsection{External Validity}
\todo{Find something here}

\subsection{Generalizability:}
Interview results may not be generalizable to all developers. In order to reduce this effect, interview participants were selected from open- and closed-source projects, varying industries, and varying project sizes (see Table \ref{interview_demographics}). Next, we confirmed our interview findings in a survey of 226 developers to ensure that results applied to a more diverse population. Additionally, our recruitment of participants through digital communication methods is subject to self-selection bias and non-response bias.

\textbf{Response Rates:}
Traditionally, survey response rates are calculated to ensure that the responding population is representative of the whole population. However, when using far-reaching methods of survey distribution such as social media or mailing lists, we have no way of knowing how many people our survey invitation reached.

\subsection{Reliability:}
For purposes of replication, our interview script and survey questions are available at \cite{companion_site}. 
\todo{Make sure survey questions actually get posted on the website before submitting}
